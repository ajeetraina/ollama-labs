name: Deploy Hugo site to GitHub Pages

on:
  push:
    branches:
      - main

permissions:
  contents: write

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: 'latest'
          extended: true

      - name: Clean existing files
        run: |
          rm -rf themes/ content/ static/ config.* layouts/ public/ data/ archetypes/

      - name: Create basic Hugo site
        run: |
          # Create a new Hugo site
          hugo new site . --force
          
          # Install Docsy theme
          git clone --depth 1 https://github.com/google/docsy.git themes/docsy
          cd themes/docsy
          npm install
          cd ../..
          
          # Create config.toml
          cat > config.toml << 'EOL'
          baseURL = "https://ajeetraina.github.io/ollama-labs/"
          title = "Ollama Labs"
          theme = "docsy"
          
          # Language settings
          contentDir = "content/en"
          defaultContentLanguage = "en"
          defaultContentLanguageInSubdir = false
          
          # Highlighting config
          pygmentsCodeFences = true
          pygmentsUseClasses = false
          pygmentsUseClassic = false
          
          # Configure how URLs look like
          [permalinks]
          blog = "/:section/:year/:month/:day/:slug/"
          
          [params]
            copyright = "The Collabnix Community"
            privacy_policy = "https://collabnix.com/privacy-policy/"
            
            # Menu title if your navbar has a versions selector to access old versions of your site.
            version_menu = "Releases"
            
            # Flag used in the "version-banner" partial to decide whether to display a 
            # banner on every page indicating that this is an archived version of the docs.
            # Set this flag to "true" if you want to display the banner.
            archived_version = false
            
            # The version number for the version of the docs represented in this doc set.
            # Used in the "version-banner" partial to display a version number for the 
            # current doc set.
            version = "0.0"
            
            # A link to latest version of the docs. Used in the "version-banner" partial to
            # point people to the main doc site.
            url_latest_version = "https://ollama.collabnix.com"
            
            # Repository configuration (URLs for in-page links to opening issues and suggesting changes)
            github_repo = "https://github.com/ajeetraina/ollama-labs"
            # An optional link to a related project repo. For example, the sibling repository where your product code lives.
            github_project_repo = "https://github.com/ollama/ollama"
            
            # Enable Algolia DocSearch
            algolia_docsearch = false
            
            # Specify a value here if your content directory is not in your repo's root directory
            github_subdir = ""
            
            # Google Custom Search Engine ID. Remove or comment out to disable search.
            gcs_engine_id = "d72aa9b2712488cc3"
            
            # Enable Lunr.js offline search
            offlineSearch = false
            
            # Enable syntax highlighting and copy buttons on code blocks with Prism
            prism_syntax_highlighting = false
            
          [[menu.main]]
            name = "Documentation"
            weight = 1
            url = "/docs/"
          
          [[menu.main]]
            name = "Labs"
            weight = 2
            url = "/labs/"
            
          [[menu.main]]
            name = "Collabnix Community"
            weight = 3
            url = "https://collabnix.com"
            pre = "<i class='fas fa-globe'></i>"
          EOL
          
          # Create content structure
          mkdir -p content/en/docs content/en/labs content/en/_index.md
          
          # Create homepage
          cat > content/en/_index.html << 'EOL'
          ---
          title: "Ollama Labs"
          linkTitle: "Ollama Labs"
          ---
          
          {{< blocks/cover title="Welcome to Ollama Labs" image_anchor="top" height="full" color="orange" >}}
          <div class="mx-auto">
            <a class="btn btn-lg btn-primary mr-3 mb-4" href="{{< relref "/docs" >}}">
              Learn More <i class="fas fa-arrow-alt-circle-right ml-2"></i>
            </a>
            <a class="btn btn-lg btn-secondary mr-3 mb-4" href="{{< relref "/labs" >}}">
              Try Labs <i class="fab fa-github ml-2 "></i>
            </a>
            <p class="lead mt-5">Your comprehensive resource for running LLMs locally using Ollama</p>
          </div>
          {{< /blocks/cover >}}
          
          {{< blocks/section >}}
          <div class="col-12">
            <h1 class="text-center">What is Ollama?</h1>
            <p class="text-center">Ollama is an open-source project that allows you to run large language models (LLMs) locally on your own hardware. It simplifies the process of downloading, installing, and running AI models without needing specialized knowledge or hardware.</p>
          </div>
          {{< /blocks/section >}}
          
          {{< blocks/section >}}
          <div class="col-4">
            <h2>Documentation</h2>
            <p>Comprehensive guides on installation, configuration, and usage</p>
            <a href="{{< relref "/docs" >}}">Read Documentation →</a>
          </div>
          <div class="col-4">
            <h2>Labs</h2>
            <p>Hands-on exercises to build practical applications</p>
            <a href="{{< relref "/labs" >}}">Try Labs →</a>
          </div>
          <div class="col-4">
            <h2>Community</h2>
            <p>Join the Collabnix Community to connect with other users</p>
            <a href="https://collabnix.com">Visit Community →</a>
          </div>
          {{< /blocks/section >}}
          EOL
          
          # Create documentation section
          cat > content/en/docs/_index.md << 'EOL'
          ---
          title: "Documentation"
          linkTitle: "Documentation"
          weight: 1
          menu:
            main:
              weight: 1
          ---
          
          Welcome to the Ollama documentation. Here you'll find comprehensive guides and documentation to help you start working with Ollama as quickly as possible.
          EOL
          
          # Create Getting Started page
          mkdir -p content/en/docs/getting-started
          cat > content/en/docs/getting-started/_index.md << 'EOL'
          ---
          title: "Getting Started"
          linkTitle: "Getting Started"
          weight: 1
          description: >-
            A guide to help you get started with Ollama
          ---
          
          # Getting Started with Ollama
          
          This guide will help you install Ollama and run your first language model locally.
          
          ## Installation
          
          Ollama is available for macOS, Linux, and Windows.
          
          ### macOS
          
          ```bash
          brew install ollama
          ```
          
          ### Linux
          
          ```bash
          curl -fsSL https://ollama.ai/install.sh | sh
          ```
          
          ### Windows
          
          Windows support is available through WSL (Windows Subsystem for Linux).
          
          ## Running Your First Model
          
          Once you have Ollama installed, you can run your first model with a simple command:
          
          ```bash
          ollama run llama2
          ```
          
          This will download the Llama 2 model (if you don't already have it) and start a chat session.
          EOL
          
          # Create Models page
          mkdir -p content/en/docs/models
          cat > content/en/docs/models/_index.md << 'EOL'
          ---
          title: "Models"
          linkTitle: "Models"
          weight: 2
          description: >-
            Information about models available in Ollama
          ---
          
          # Ollama Model Library
          
          Ollama supports a wide variety of open-source large language models (LLMs). This section provides information about the most popular models available for use with Ollama.
          
          ## Available Models
          
          Here's an overview of the main models available for Ollama:
          
          | Model | Size | Strengths | Ideal Use Cases |
          |-------|------|-----------|----------------|
          | Llama 2 | 7B to 70B | Well-balanced performance | General purpose, chat, coding |
          | Mistral | 7B | Strong at reasoning | Creative writing, complex reasoning |
          | Gemma | 2B, 7B | Google's lightweight model | Simple tasks, embedded systems |
          | Phi | 2B | Microsoft's small but capable model | Education, lightweight applications |
          EOL
          
          # Create labs section
          cat > content/en/labs/_index.md << 'EOL'
          ---
          title: "Labs"
          linkTitle: "Labs"
          weight: 2
          menu:
            main:
              weight: 2
          ---
          
          # Ollama Labs
          
          Welcome to Ollama Labs, where you'll find hands-on exercises to help you build practical applications with Ollama.
          EOL
          
          # Create Lab 1
          mkdir -p content/en/labs/lab1
          cat > content/en/labs/lab1/_index.md << 'EOL'
          ---
          title: "Lab 1: Running Your First Model"
          linkTitle: "Lab 1: First Model"
          weight: 1
          description: >-
            Learn how to run your first language model with Ollama
          ---
          
          # Lab 1: Running Your First Model with Ollama
          
          In this lab, you'll learn how to run your first language model using Ollama and interact with it through the command line.
          
          ## Prerequisites
          
          - Ollama installed on your system
          - Terminal or command prompt access
          - At least 5GB of free disk space
          
          ## Step 1: Verify Ollama Installation
          
          ```bash
          ollama --version
          ```
          
          ## Step 2: Run Your First Model
          
          ```bash
          ollama run llama2
          ```
          
          This will download the model if needed and start an interactive chat session.
          EOL
          
          # Create Lab 2
          mkdir -p content/en/labs/lab2
          cat > content/en/labs/lab2/_index.md << 'EOL'
          ---
          title: "Lab 2: Python Integration"
          linkTitle: "Lab 2: Python Integration"
          weight: 2
          description: >-
            Learn how to use Ollama from Python applications
          ---
          
          # Lab 2: Integrating Ollama with Python
          
          In this lab, you'll learn how to use Ollama from Python applications.
          
          ## Prerequisites
          
          - Ollama installed and working
          - Python 3.8 or newer
          - Basic Python knowledge
          
          ## Example Python Code
          
          ```python
          import requests
          import json
          
          def generate_response(prompt, model="llama2"):
              url = "http://localhost:11434/api/generate"
              
              data = {
                  "model": model,
                  "prompt": prompt
              }
              
              response = requests.post(url, json=data)
              if response.status_code == 200:
                  response_text = ""
                  for line in response.text.strip().split('\n'):
                      try:
                          response_json = json.loads(line)
                          if 'response' in response_json:
                              response_text += response_json['response']
                      except json.JSONDecodeError:
                          pass
                  return response_text
              else:
                  return f"Error: {response.status_code} - {response.text}"
          ```
          EOL
          
          mkdir -p static/images
          
          echo "Finished setting up basic site with Docsy theme"

      - name: Install PostCSS for Docsy
        run: |
          npm install -D autoprefixer
          npm install -D postcss-cli

      - name: Build site
        run: hugo --minify

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages
          cname: ollama.collabnix.com